{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q1B_ClassificationTask.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G58G9ZUQ4r1Y"
      },
      "source": [
        "# **Question 1b:** Classification Task\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Imports**\n",
        "\n",
        "Import needed libraries and download packages \"punkt\" and \"popular\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugn6Q1_33sM3",
        "outputId": "0b4b6e7f-25b2-4f54-d09a-b38d4c06b34f"
      },
      "source": [
        "import pandas as pd\n",
        "from string import digits\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('popular')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrBDg9HUqVAc"
      },
      "source": [
        "Code to mount google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91u5kE3I_Imf",
        "outputId": "1c8a54b4-9e0b-46fe-9ed1-a704bcece758"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSxUxwZ1qbir"
      },
      "source": [
        "Read train and test data in dataframes from csv files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6xjtS54Cej1q",
        "outputId": "36eb6a86-f99e-4e4c-e591-d87637caa0e5"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/University/datasets2020/datasets/q1/train.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>227464</td>\n",
              "      <td>Netflix is coming to cable boxes, and Amazon i...</td>\n",
              "      <td>if you subscribe to one of three rinky-dink (...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>244074</td>\n",
              "      <td>Pharrell, Iranian President React to Tehran 'H...</td>\n",
              "      <td>pharrell, iranian president react to tehran '...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60707</td>\n",
              "      <td>Wildlife service seeks comments</td>\n",
              "      <td>the u.s. fish and wildlife service has reopen...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27883</td>\n",
              "      <td>Facebook teams up with Storyful to launch 'FB ...</td>\n",
              "      <td>the very nature of social media means it is o...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>169596</td>\n",
              "      <td>Caesars plans US$880 mln New York casino</td>\n",
              "      <td>caesars plans us$880 mln new york casino jul ...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Id  ...          Label\n",
              "0  227464  ...  Entertainment\n",
              "1  244074  ...  Entertainment\n",
              "2   60707  ...     Technology\n",
              "3   27883  ...     Technology\n",
              "4  169596  ...       Business\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "cJHlXvTWWtSE",
        "outputId": "6dbc2851-7535-4367-b439-830a3b417e8a"
      },
      "source": [
        "df_test = pd.read_csv(\"/content/drive/MyDrive/University/datasets2020/datasets/q1/test_without_labels.csv\")\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262120</td>\n",
              "      <td>Tracy Morgan upgraded to fair condition after ...</td>\n",
              "      <td>actor and comedian tracy morgan has been upgr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175132</td>\n",
              "      <td>Smartphones Weigh on Samsung Electronics as Gu...</td>\n",
              "      <td>samsung electronics co ltd on tuesday issued u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>218739</td>\n",
              "      <td>FBI denies fumbling testimony on 'X-Men' direc...</td>\n",
              "      <td>michael f. egan iii said in a press conferenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>253483</td>\n",
              "      <td>Bachelorette 2014 Spoilers: Week 3 Recap ??? E...</td>\n",
              "      <td>i am having mixed emotions for what is about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>224109</td>\n",
              "      <td>Barack Obama honours Frankie Knuckles in lette...</td>\n",
              "      <td>u.s. president barack obama has paid a specia...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Id  ...                                            Content\n",
              "0  262120  ...   actor and comedian tracy morgan has been upgr...\n",
              "1  175132  ...  samsung electronics co ltd on tuesday issued u...\n",
              "2  218739  ...   michael f. egan iii said in a press conferenc...\n",
              "3  253483  ...   i am having mixed emotions for what is about ...\n",
              "4  224109  ...   u.s. president barack obama has paid a specia...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9-gZZB-Q-Dj"
      },
      "source": [
        "# **Text Data Cleaning**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        ">For the data cleaning process, we included the following:\n",
        "* Remove all whitespaces and newlines \n",
        "* Remove all special characters and punctuation\n",
        "* Replace contractions with full words (despite that they might be removed   later from the stopwords)\n",
        "* Splitted attached words e.g.  “ForTheWin” =>  “For The Win”\n",
        "* Lowered all capital letters  \n",
        ">We tried removing the numbers from the text corpus and standarizing the sentences but it was proved to have no effect in our model's performance.\n",
        "\n",
        ">As a rule, the Title of an article is a strong indicator of the content that follows. We need the Title to have high importance/weight in our data. Thus we concatenate the Title *three* times along with the Content, in a new dataframe column, named *Title Content*. This is the column we process and use to train our classifiers later.\n",
        "\n",
        ">Both train and test data are preprocessed in the same exact way.\n",
        "\n",
        ">(reference link: [python-efficient-text-data-cleaning](https://www.geeksforgeeks.org/python-efficient-text-data-cleaning/)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Z3tw4UOvjgbT",
        "outputId": "b2dca923-9527-4de2-c435-aec18b97c8e1"
      },
      "source": [
        "def numbers(x):\n",
        "  return re.sub(r'[0-9]+', '', x)\n",
        "\n",
        "def blank_space(x):\n",
        "  return re.sub('[^A-Za-z0-9]+', ' ', x)\n",
        "\n",
        "def standarize_sentence(x):\n",
        "  return ''.join(''.join(word)[:2] for word in x) \n",
        "\n",
        "def apostrophe_words(x):\n",
        "  Apos_dict={\"'s\":\" is\",\"'t\":\" not\",\"'m\":\" am\",\"'ll\":\" will\", \"'d\":\" would\",\"'ve\":\" have\",\"'re\":\" are\", \n",
        "             \"’s\":\" is\",\"’t\":\" not\",\"’m\":\" am\", \"’d\":\" would\",\"’ve\":\" have\",\"’re\":\" are\", \"’ll\": \"will\"} \n",
        "  for key,value in Apos_dict.items(): \n",
        "    if key in x:\n",
        "      x =  x.replace(key,value)\n",
        "      return x\n",
        "  return x\n",
        "\n",
        "def split_words(x):\n",
        "  return \" \".join([word for word in re.split(\"([A-Z][a-z]+[^A-Z]*)\",x) if word])\n",
        "\n",
        "def shallow_cleaning(df):\n",
        "  remove_digits = str.maketrans('', '', digits)\n",
        "  df['Title Content'] = df['Title Content'].apply(lambda x: blank_space(x))\n",
        "  #df['Title Content'] = df['Title Content'].apply(lambda x: numbers(x))\n",
        "  #df['Title Content'] = df['Title Content'].apply(lambda x: split_words(x))\n",
        "  #df['Title Content'] = df['Title Content'].apply(lambda x: standarize_sentence(x))\n",
        "  df['Title Content'] = df['Title Content'].apply(lambda x: apostrophe_words(x))\n",
        "  df['Title Content'] = df['Title Content'].str.strip()\n",
        "  df['Title Content'] = df['Title Content'].str.lower()\n",
        "  return df\n",
        "\n",
        "df['Title Content'] = pd.DataFrame(df['Title'] + ' ' + df['Title'] + ' ' + df['Title'] + ' ' + df['Content'])\n",
        "df = shallow_cleaning(df)\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Label</th>\n",
              "      <th>Title Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>227464</td>\n",
              "      <td>Netflix is coming to cable boxes, and Amazon i...</td>\n",
              "      <td>if you subscribe to one of three rinky-dink (...</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>netflix is coming to cable boxes and amazon is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>244074</td>\n",
              "      <td>Pharrell, Iranian President React to Tehran 'H...</td>\n",
              "      <td>pharrell, iranian president react to tehran '...</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>pharrell iranian president react to tehran hap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60707</td>\n",
              "      <td>Wildlife service seeks comments</td>\n",
              "      <td>the u.s. fish and wildlife service has reopen...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>wildlife service seeks comments wildlife servi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27883</td>\n",
              "      <td>Facebook teams up with Storyful to launch 'FB ...</td>\n",
              "      <td>the very nature of social media means it is o...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>facebook teams up with storyful to launch fb n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>169596</td>\n",
              "      <td>Caesars plans US$880 mln New York casino</td>\n",
              "      <td>caesars plans us$880 mln new york casino jul ...</td>\n",
              "      <td>Business</td>\n",
              "      <td>caesars plans us 880 mln new york casino caesa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111790</th>\n",
              "      <td>31462</td>\n",
              "      <td>Microsoft requires Office 2013 licensing for s...</td>\n",
              "      <td>in contrast to the muckle of special licenses...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>microsoft requires office 2013 licensing for s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111791</th>\n",
              "      <td>100821</td>\n",
              "      <td>Smallpox vials missing since 1950s found in la...</td>\n",
              "      <td>government workers at a research center near ...</td>\n",
              "      <td>Health</td>\n",
              "      <td>smallpox vials missing since 1950s found in la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111792</th>\n",
              "      <td>86181</td>\n",
              "      <td>Scientists May Have Just Discovered the Key to...</td>\n",
              "      <td>harvard scientists may have just unlocked the...</td>\n",
              "      <td>Health</td>\n",
              "      <td>scientists may have just discovered the key to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111793</th>\n",
              "      <td>256423</td>\n",
              "      <td>Justin Bieber to plead guilty to DUI</td>\n",
              "      <td>justin bieber to plead guilty to duifri, 13 ju...</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>justin bieber to plead guilty to dui justin bi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111794</th>\n",
              "      <td>262120</td>\n",
              "      <td>Tracy Morgan upgraded to fair condition after ...</td>\n",
              "      <td>actor and comedian tracy morgan has been upgr...</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>tracy morgan upgraded to fair condition after ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>111795 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Id  ...                                      Title Content\n",
              "0       227464  ...  netflix is coming to cable boxes and amazon is...\n",
              "1       244074  ...  pharrell iranian president react to tehran hap...\n",
              "2        60707  ...  wildlife service seeks comments wildlife servi...\n",
              "3        27883  ...  facebook teams up with storyful to launch fb n...\n",
              "4       169596  ...  caesars plans us 880 mln new york casino caesa...\n",
              "...        ...  ...                                                ...\n",
              "111790   31462  ...  microsoft requires office 2013 licensing for s...\n",
              "111791  100821  ...  smallpox vials missing since 1950s found in la...\n",
              "111792   86181  ...  scientists may have just discovered the key to...\n",
              "111793  256423  ...  justin bieber to plead guilty to dui justin bi...\n",
              "111794  262120  ...  tracy morgan upgraded to fair condition after ...\n",
              "\n",
              "[111795 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "GlIcK-j1M-uO",
        "outputId": "b5dcd471-0481-4cec-add3-a85f1d907d75"
      },
      "source": [
        "df_test['Title Content'] = pd.DataFrame(df_test['Title'] + ' ' + df_test['Title'] + ' ' + df_test['Title'] + ' ' + df_test['Content'])\n",
        "df_test = shallow_cleaning(df_test)\n",
        "display(df_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Title Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262120</td>\n",
              "      <td>Tracy Morgan upgraded to fair condition after ...</td>\n",
              "      <td>actor and comedian tracy morgan has been upgr...</td>\n",
              "      <td>tracy morgan upgraded to fair condition after ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175132</td>\n",
              "      <td>Smartphones Weigh on Samsung Electronics as Gu...</td>\n",
              "      <td>samsung electronics co ltd on tuesday issued u...</td>\n",
              "      <td>smartphones weigh on samsung electronics as gu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>218739</td>\n",
              "      <td>FBI denies fumbling testimony on 'X-Men' direc...</td>\n",
              "      <td>michael f. egan iii said in a press conferenc...</td>\n",
              "      <td>fbi denies fumbling testimony on x men directo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>253483</td>\n",
              "      <td>Bachelorette 2014 Spoilers: Week 3 Recap ??? E...</td>\n",
              "      <td>i am having mixed emotions for what is about ...</td>\n",
              "      <td>bachelorette 2014 spoilers week 3 recap eric h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>224109</td>\n",
              "      <td>Barack Obama honours Frankie Knuckles in lette...</td>\n",
              "      <td>u.s. president barack obama has paid a specia...</td>\n",
              "      <td>barack obama honours frankie knuckles in lette...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47907</th>\n",
              "      <td>50348</td>\n",
              "      <td>BMW, Tesla meet to discuss standardizing elect...</td>\n",
              "      <td>june 16, 2014 by edward taylor reutersan emplo...</td>\n",
              "      <td>bmw tesla meet to discuss standardizing electr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47908</th>\n",
              "      <td>255044</td>\n",
              "      <td>Harrison Ford has been filming the seventh Sta...</td>\n",
              "      <td>he may have helped save the galaxy from the ev...</td>\n",
              "      <td>harrison ford has been filming the seventh sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47909</th>\n",
              "      <td>66502</td>\n",
              "      <td>It's Games, Games, Games As Microsoft Plans To...</td>\n",
              "      <td>less than three months after microsoft had a ...</td>\n",
              "      <td>it s games games games as microsoft plans to c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47910</th>\n",
              "      <td>10319</td>\n",
              "      <td>App Detail » Microsoft Excel for iPad</td>\n",
              "      <td>app description *** excel is ready for ipad p...</td>\n",
              "      <td>app detail microsoft excel for ipad app detail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47911</th>\n",
              "      <td>48751</td>\n",
              "      <td>Starbucks Makes Itself More Addictive With Wir...</td>\n",
              "      <td>soon, you'll be able to recharge at starbucks...</td>\n",
              "      <td>starbucks makes itself more addictive with wir...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47912 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Id  ...                                      Title Content\n",
              "0      262120  ...  tracy morgan upgraded to fair condition after ...\n",
              "1      175132  ...  smartphones weigh on samsung electronics as gu...\n",
              "2      218739  ...  fbi denies fumbling testimony on x men directo...\n",
              "3      253483  ...  bachelorette 2014 spoilers week 3 recap eric h...\n",
              "4      224109  ...  barack obama honours frankie knuckles in lette...\n",
              "...       ...  ...                                                ...\n",
              "47907   50348  ...  bmw tesla meet to discuss standardizing electr...\n",
              "47908  255044  ...  harrison ford has been filming the seventh sta...\n",
              "47909   66502  ...  it s games games games as microsoft plans to c...\n",
              "47910   10319  ...  app detail microsoft excel for ipad app detail...\n",
              "47911   48751  ...  starbucks makes itself more addictive with wir...\n",
              "\n",
              "[47912 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eorIOzuSZTlz"
      },
      "source": [
        "## Stemming\n",
        "\n",
        "To enhance the classification performance we proceeded to stem the data of *Title Content* column. \n",
        "\n",
        "Stemming is a Text Normalization (or sometimes called Word Normalization) techniques in the field of Natural Language Processing that are used to prepare text, words, and documents for further processing. Stemming helps us to achieve the root forms (sometimes called synonyms in search context) of inflected (derived) words. Thus, we define as Stem (root) the part of the word to which we add inflectional (changing/deriving) affixes such as (-ed,-ize, -s,-de,mis). So stemming a word or sentence may result in words that are not actual words. Stems are created by removing the suffixes or prefixes used with a word.\n",
        "\n",
        "For this process we used PorterStemmer for the English language. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_tv2Kc7uo-Jd",
        "outputId": "86948805-cced-4544-a094-1ebf8becf0ca"
      },
      "source": [
        "porter = PorterStemmer()\n",
        "\n",
        "df['Title Content'] = df['Title Content'].apply(lambda x: word_tokenize(x))\n",
        "df['Title Content'] = df['Title Content'].apply(lambda x: [porter.stem(word) for word in x])\n",
        "df['Title Content'] = df['Title Content'].apply(lambda x: ' '.join(str(word) for word in x))\n",
        "\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Label</th>\n",
              "      <th>Title Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>227464</td>\n",
              "      <td>Netflix is coming to cable boxes, and Amazon i...</td>\n",
              "      <td>if you subscribe to one of three rinky-dink (...</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>netflix is come to cabl box and amazon is now ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>244074</td>\n",
              "      <td>Pharrell, Iranian President React to Tehran 'H...</td>\n",
              "      <td>pharrell, iranian president react to tehran '...</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>pharrel iranian presid react to tehran happi a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60707</td>\n",
              "      <td>Wildlife service seeks comments</td>\n",
              "      <td>the u.s. fish and wildlife service has reopen...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>wildlif servic seek comment wildlif servic see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27883</td>\n",
              "      <td>Facebook teams up with Storyful to launch 'FB ...</td>\n",
              "      <td>the very nature of social media means it is o...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>facebook team up with story to launch fb newsw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>169596</td>\n",
              "      <td>Caesars plans US$880 mln New York casino</td>\n",
              "      <td>caesars plans us$880 mln new york casino jul ...</td>\n",
              "      <td>Business</td>\n",
              "      <td>caesar plan us 880 mln new york casino caesar ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Id  ...                                      Title Content\n",
              "0  227464  ...  netflix is come to cabl box and amazon is now ...\n",
              "1  244074  ...  pharrel iranian presid react to tehran happi a...\n",
              "2   60707  ...  wildlif servic seek comment wildlif servic see...\n",
              "3   27883  ...  facebook team up with story to launch fb newsw...\n",
              "4  169596  ...  caesar plan us 880 mln new york casino caesar ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "P399HO0ryHBl",
        "outputId": "64af6d2d-bf05-461a-f9f8-86614f3277bd"
      },
      "source": [
        "df_test['Title Content'] = df_test['Title Content'].apply(lambda x: word_tokenize(x))\n",
        "df_test['Title Content'] = df_test['Title Content'].apply(lambda x: [porter.stem(word) for word in x])\n",
        "df_test['Title Content'] = df_test['Title Content'].apply(lambda x: ' '.join(str(word) for word in x))\n",
        "\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Title Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262120</td>\n",
              "      <td>Tracy Morgan upgraded to fair condition after ...</td>\n",
              "      <td>actor and comedian tracy morgan has been upgr...</td>\n",
              "      <td>traci morgan upgrad to fair condit after crash...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175132</td>\n",
              "      <td>Smartphones Weigh on Samsung Electronics as Gu...</td>\n",
              "      <td>samsung electronics co ltd on tuesday issued u...</td>\n",
              "      <td>smartphon weigh on samsung electron as guidanc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>218739</td>\n",
              "      <td>FBI denies fumbling testimony on 'X-Men' direc...</td>\n",
              "      <td>michael f. egan iii said in a press conferenc...</td>\n",
              "      <td>fbi deni fumbl testimoni on x men director bry...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>253483</td>\n",
              "      <td>Bachelorette 2014 Spoilers: Week 3 Recap ??? E...</td>\n",
              "      <td>i am having mixed emotions for what is about ...</td>\n",
              "      <td>bachelorett 2014 spoiler week 3 recap eric hil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>224109</td>\n",
              "      <td>Barack Obama honours Frankie Knuckles in lette...</td>\n",
              "      <td>u.s. president barack obama has paid a specia...</td>\n",
              "      <td>barack obama honour franki knuckl in letter to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Id  ...                                      Title Content\n",
              "0  262120  ...  traci morgan upgrad to fair condit after crash...\n",
              "1  175132  ...  smartphon weigh on samsung electron as guidanc...\n",
              "2  218739  ...  fbi deni fumbl testimoni on x men director bry...\n",
              "3  253483  ...  bachelorett 2014 spoiler week 3 recap eric hil...\n",
              "4  224109  ...  barack obama honour franki knuckl in letter to...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnED1FsYenk3",
        "outputId": "ecd1205a-2bfb-46f5-e6bd-60901bef8cbb"
      },
      "source": [
        "df.Label.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Entertainment', 'Technology', 'Business', 'Health'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRITd4gkzfgG"
      },
      "source": [
        "## Creating Bag of Words\n",
        "\n",
        ">Appending some extra words in the stopwords' list provided by nltk library. Creating a representative list of stopwords for the dataset at hand, helps to suppress as much as possible the noise of words that do not really play a key role in the classification process (chances are that they are just indifferent to the article's meaning and as the result to the classification result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L75EVPpvj_8E"
      },
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "stop_words.append(\"said\")\n",
        "stop_words.append(\"say\")\n",
        "stop_words.append(\"says\")\n",
        "stop_words.append(\"one\")\n",
        "stop_words.append(\"also\")\n",
        "stop_words.append(\"may\")\n",
        "stop_words.append(\"will\")\n",
        "stop_words.append(\"seem\")\n",
        "stop_words.append(\"many\")\n",
        "stop_words.append(\"much\")\n",
        "stop_words.append(\"think\")\n",
        "stop_words.append(\"like\")\n",
        "stop_words.append(\"would\")\n",
        "stop_words.append(\"even\")\n",
        "stop_words.append(\"well\")\n",
        "stop_words.append(\"time\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YPImFKHcPQs"
      },
      "source": [
        "## Tfidf Vectorizer\n",
        "\n",
        "We use the tfidf vectorizer to create the bag of words. TF-IDF stands for Term Frequency-Inverse Document Frequency. The Bag of Words (BoW) model is the simplest form of text representation in numbers. Like the term itself, we can represent a sentence as a bag of words vector (a string of numbers). A simple Bag of Words (like one created with the use of CountVectorizer class), just creates a set of vectors containing the count of word occurrences in the corpus given. On the other hand, the TF-IDF model contains information on the more important words and the less important ones as well. In this case we create select to contain the size of the information to 10000 features. This number comes after multiple trials with various different numbers of features. But if we either defined more (e.g. max_features=20000 etc.) or less (e.g. max_features=2000 etc.), during the classification the cross validation metrics were significantly deteriorating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUEjiulce0Zg",
        "outputId": "25452435-823f-46ed-9df6-cda160b0dc16"
      },
      "source": [
        "vectorizer=TfidfVectorizer(max_features=10000, stop_words=stop_words, ngram_range=(1, 2))\n",
        "\n",
        "temp = df['Title Content']\n",
        "labels = df['Label']\n",
        "\n",
        "vectorized_content = vectorizer.fit_transform(temp)\n",
        "train_bow = vectorized_content\n",
        "train_bow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<111795x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 18064785 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSyqJ9bpWirF",
        "outputId": "5fcf771d-f862-47dc-8595-cb11155c7049"
      },
      "source": [
        "temp = df_test['Title Content']\n",
        "\n",
        "vectorized_test_content = vectorizer.fit_transform(temp)\n",
        "test_bow = vectorized_test_content\n",
        "test_bow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<47912x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 7751755 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McJUPC3EgPGl"
      },
      "source": [
        "**Label encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49otmL5FLqNh",
        "outputId": "de8eb93c-298c-4308-9850-0e063e974c9a"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "label_enc = preprocessing.LabelEncoder()\n",
        "labels = label_enc.fit_transform(df['Label'])\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, ..., 2, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4uD0KFZgUnG"
      },
      "source": [
        "Useful method declarations for csv file creation and statistics calculation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRn8cLw8MqL2"
      },
      "source": [
        "def create_file(data, prediction, filename):\n",
        "  res_df = pd.DataFrame(data)\n",
        "  res_df['Predicted'] = label_enc.inverse_transform(prediction)\n",
        "  res_df.to_csv(filename+\".csv\", columns=['Id', 'Predicted'], index=False)\n",
        "  return res_df\n",
        "\n",
        "res_mean = pd.DataFrame([])\n",
        "res_mean = res_mean.rename_axis('Statistic Measure', axis=1)\n",
        "columnNum=0\n",
        "def calculate_statistic_metrics(res, res_mean, columnName, columnNum):\n",
        "  temp_df = pd.DataFrame([])\n",
        "  accuracy_mean = pd.Series(res['test_accuracy'].mean(), name='Accuracy')\n",
        "  precision_mean = pd.Series(res['test_precision_macro'].mean(), name='Precision')\n",
        "  recall_mean = pd.Series(res['test_recall_macro'].mean(), name='Recall')\n",
        "  F1_mean = pd.Series(res['test_f1_macro'].mean(), name='F-measure')\n",
        "  temp_df = temp_df.append(accuracy_mean)\n",
        "  temp_df = temp_df.append(precision_mean)\n",
        "  temp_df = temp_df.append(recall_mean)\n",
        "  temp_df = temp_df.append(F1_mean)\n",
        "  res_mean[columnName] = temp_df[0]\n",
        "  res_mean = res_mean.rename(columns={columnNum:columnName})\n",
        "  return res_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4_-uLBCvOYu"
      },
      "source": [
        "#**Classification Task**\n",
        "For each algorithm's parameters we conducted multiple experiments in order to determine the best combination with the data.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "##**Classification Algorithms + Bag Of Words**\n",
        "\n",
        "### **SVM**\n",
        "\n",
        ">For the SVM i used the sklearn function [LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html). LinearSVC is similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and also scales better to large numbers of data samples. This class supports both dense and sparse input and the multiclass support is handled according to a one-vs-the-rest scheme.\n",
        "\n",
        "### **5-Fold Cross Validation**\n",
        ">According to the 5-Fold cross validation over the test data, the linear svm model given the BoW we created before, scores high in all the metrics we consider. This cross validation indicates that our trained model should predict the class of each article correctly (True-Positive) 96,8% of the times, while it presents to have really low instances of False-Positive class predictions. Overall the model's accuracy reaches the score of 97%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5QxJf7n4Mwt"
      },
      "source": [
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_hx-0bze4I5"
      },
      "source": [
        "X=train_bow\n",
        "y=labels\n",
        "clf = LinearSVC(random_state=42, tol=1e-5, C=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "nN01zs2DSVl6",
        "outputId": "a5efbbd4-a189-41b9-d654-c19c4a7c3081"
      },
      "source": [
        "scoring=['accuracy','precision_macro', 'recall_macro', 'f1_macro']\n",
        "scores = cross_validate(clf, X, y, cv=5, n_jobs=4, scoring=scoring)\n",
        "svm_res = pd.DataFrame.from_dict(scores)\n",
        "res_mean = calculate_statistic_metrics(svm_res, res_mean, 'SVM (BoW)', columnNum)\n",
        "display(res_mean)\n",
        "res_mean.to_csv('evaluationResults.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Statistic Measure</th>\n",
              "      <th>SVM (BoW)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.970008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.968411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.965929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F-measure</th>\n",
              "      <td>0.967147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Statistic Measure  SVM (BoW)\n",
              "Accuracy            0.970008\n",
              "Precision           0.968411\n",
              "Recall              0.965929\n",
              "F-measure           0.967147"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l44rLdV1Q1SZ"
      },
      "source": [
        "Make prediction for the test data with svm model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "JQ4FyNfshEdg",
        "outputId": "f5943113-e050-4ed4-fca7-bc1ca8748d7e"
      },
      "source": [
        "clf.fit(X, y)\n",
        "y_pred_test = clf.predict(test_bow)\n",
        "svm_bow_pred_df = create_file(df_test, y_pred_test, 'svm_bow_pred')\n",
        "display(svm_bow_pred_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Title Content</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262120</td>\n",
              "      <td>Tracy Morgan upgraded to fair condition after ...</td>\n",
              "      <td>actor and comedian tracy morgan has been upgr...</td>\n",
              "      <td>traci morgan upgrad to fair condit after crash...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175132</td>\n",
              "      <td>Smartphones Weigh on Samsung Electronics as Gu...</td>\n",
              "      <td>samsung electronics co ltd on tuesday issued u...</td>\n",
              "      <td>smartphon weigh on samsung electron as guidanc...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>218739</td>\n",
              "      <td>FBI denies fumbling testimony on 'X-Men' direc...</td>\n",
              "      <td>michael f. egan iii said in a press conferenc...</td>\n",
              "      <td>fbi deni fumbl testimoni on x men director bry...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>253483</td>\n",
              "      <td>Bachelorette 2014 Spoilers: Week 3 Recap ??? E...</td>\n",
              "      <td>i am having mixed emotions for what is about ...</td>\n",
              "      <td>bachelorett 2014 spoiler week 3 recap eric hil...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>224109</td>\n",
              "      <td>Barack Obama honours Frankie Knuckles in lette...</td>\n",
              "      <td>u.s. president barack obama has paid a specia...</td>\n",
              "      <td>barack obama honour franki knuckl in letter to...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47907</th>\n",
              "      <td>50348</td>\n",
              "      <td>BMW, Tesla meet to discuss standardizing elect...</td>\n",
              "      <td>june 16, 2014 by edward taylor reutersan emplo...</td>\n",
              "      <td>bmw tesla meet to discuss standard electr car ...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47908</th>\n",
              "      <td>255044</td>\n",
              "      <td>Harrison Ford has been filming the seventh Sta...</td>\n",
              "      <td>he may have helped save the galaxy from the ev...</td>\n",
              "      <td>harrison ford ha been film the seventh star wa...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47909</th>\n",
              "      <td>66502</td>\n",
              "      <td>It's Games, Games, Games As Microsoft Plans To...</td>\n",
              "      <td>less than three months after microsoft had a ...</td>\n",
              "      <td>it s game game game as microsoft plan to close...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47910</th>\n",
              "      <td>10319</td>\n",
              "      <td>App Detail » Microsoft Excel for iPad</td>\n",
              "      <td>app description *** excel is ready for ipad p...</td>\n",
              "      <td>app detail microsoft excel for ipad app detail...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47911</th>\n",
              "      <td>48751</td>\n",
              "      <td>Starbucks Makes Itself More Addictive With Wir...</td>\n",
              "      <td>soon, you'll be able to recharge at starbucks...</td>\n",
              "      <td>starbuck make itself more addict with wireless...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47912 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Id  ...      Predicted\n",
              "0      262120  ...     Technology\n",
              "1      175132  ...  Entertainment\n",
              "2      218739  ...  Entertainment\n",
              "3      253483  ...     Technology\n",
              "4      224109  ...  Entertainment\n",
              "...       ...  ...            ...\n",
              "47907   50348  ...     Technology\n",
              "47908  255044  ...       Business\n",
              "47909   66502  ...     Technology\n",
              "47910   10319  ...     Technology\n",
              "47911   48751  ...  Entertainment\n",
              "\n",
              "[47912 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhS0OWMXvSNd"
      },
      "source": [
        "### **Random Forest**\n",
        "\n",
        ">A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. We use the classifier with its default parameters.\n",
        "\n",
        "###**5-Fold Cross Validation**\n",
        "\n",
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXMC5att4ePy"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI_BZwM9WJZ7"
      },
      "source": [
        "X=train_bow\n",
        "y=labels\n",
        "\n",
        "clf_Rf = RandomForestClassifier(n_jobs=-1, n_estimators=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "mZzzI2vKhQNm",
        "outputId": "0328c7fc-993e-4143-ab9a-19083d107b27"
      },
      "source": [
        "scoring=['accuracy','precision_macro', 'recall_macro', 'f1_macro']\n",
        "scores = cross_validate(clf_Rf, X, y, cv=5, n_jobs=4, scoring=scoring)\n",
        "rf_res = pd.DataFrame.from_dict(scores)\n",
        "res_mean = calculate_statistic_metrics(rf_res, res_mean, 'Random Forest (BoW)', columnNum)\n",
        "display(res_mean)\n",
        "res_mean.to_csv('evaluationResults')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Statistic Measure</th>\n",
              "      <th>SVM (BoW)</th>\n",
              "      <th>Random Forest (BoW)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.970008</td>\n",
              "      <td>0.939559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.968411</td>\n",
              "      <td>0.940052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.965929</td>\n",
              "      <td>0.927771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F-measure</th>\n",
              "      <td>0.967147</td>\n",
              "      <td>0.933616</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Statistic Measure  SVM (BoW)  Random Forest (BoW)\n",
              "Accuracy            0.970008             0.939559\n",
              "Precision           0.968411             0.940052\n",
              "Recall              0.965929             0.927771\n",
              "F-measure           0.967147             0.933616"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpISA8MG4CNR"
      },
      "source": [
        "Make label prediction for test data with bow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QUOKr1bWPDQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "59387c9e-3fc6-4a01-85c7-f358ca0eb960"
      },
      "source": [
        "clf_Rf.fit(X, y)\n",
        "y_pred = clf_Rf.predict(test_bow)\n",
        "rf_bow_pred_df = create_file(df_test, y_pred, 'rf_bow_pred')\n",
        "display(rf_bow_pred_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Title Content</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262120</td>\n",
              "      <td>Tracy Morgan upgraded to fair condition after ...</td>\n",
              "      <td>actor and comedian tracy morgan has been upgr...</td>\n",
              "      <td>traci morgan upgrad to fair condit after crash...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175132</td>\n",
              "      <td>Smartphones Weigh on Samsung Electronics as Gu...</td>\n",
              "      <td>samsung electronics co ltd on tuesday issued u...</td>\n",
              "      <td>smartphon weigh on samsung electron as guidanc...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>218739</td>\n",
              "      <td>FBI denies fumbling testimony on 'X-Men' direc...</td>\n",
              "      <td>michael f. egan iii said in a press conferenc...</td>\n",
              "      <td>fbi deni fumbl testimoni on x men director bry...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>253483</td>\n",
              "      <td>Bachelorette 2014 Spoilers: Week 3 Recap ??? E...</td>\n",
              "      <td>i am having mixed emotions for what is about ...</td>\n",
              "      <td>bachelorett 2014 spoiler week 3 recap eric hil...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>224109</td>\n",
              "      <td>Barack Obama honours Frankie Knuckles in lette...</td>\n",
              "      <td>u.s. president barack obama has paid a specia...</td>\n",
              "      <td>barack obama honour franki knuckl in letter to...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47907</th>\n",
              "      <td>50348</td>\n",
              "      <td>BMW, Tesla meet to discuss standardizing elect...</td>\n",
              "      <td>june 16, 2014 by edward taylor reutersan emplo...</td>\n",
              "      <td>bmw tesla meet to discuss standard electr car ...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47908</th>\n",
              "      <td>255044</td>\n",
              "      <td>Harrison Ford has been filming the seventh Sta...</td>\n",
              "      <td>he may have helped save the galaxy from the ev...</td>\n",
              "      <td>harrison ford ha been film the seventh star wa...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47909</th>\n",
              "      <td>66502</td>\n",
              "      <td>It's Games, Games, Games As Microsoft Plans To...</td>\n",
              "      <td>less than three months after microsoft had a ...</td>\n",
              "      <td>it s game game game as microsoft plan to close...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47910</th>\n",
              "      <td>10319</td>\n",
              "      <td>App Detail » Microsoft Excel for iPad</td>\n",
              "      <td>app description *** excel is ready for ipad p...</td>\n",
              "      <td>app detail microsoft excel for ipad app detail...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47911</th>\n",
              "      <td>48751</td>\n",
              "      <td>Starbucks Makes Itself More Addictive With Wir...</td>\n",
              "      <td>soon, you'll be able to recharge at starbucks...</td>\n",
              "      <td>starbuck make itself more addict with wireless...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47912 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Id  ...      Predicted\n",
              "0      262120  ...  Entertainment\n",
              "1      175132  ...     Technology\n",
              "2      218739  ...     Technology\n",
              "3      253483  ...  Entertainment\n",
              "4      224109  ...     Technology\n",
              "...       ...  ...            ...\n",
              "47907   50348  ...       Business\n",
              "47908  255044  ...       Business\n",
              "47909   66502  ...       Business\n",
              "47910   10319  ...       Business\n",
              "47911   48751  ...       Business\n",
              "\n",
              "[47912 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE_PtFwRugio"
      },
      "source": [
        "#**Classification + BoW + SVD**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### SVD\n",
        "Dimensionality reduction using [Truncated SVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) (aka LSA).\n",
        "This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). This estimator does not center the data before computing the singular value decomposition. This means it can work with sparse matrices efficiently (*Note: tfidf returns a sparse matrix*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usOTDusYuTbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66876d7-053a-4311-f094-2a519aca38ee"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "X=train_bow\n",
        "y=labels\n",
        "Z=test_bow\n",
        "\n",
        "svd = TruncatedSVD(n_components=100, random_state=42)\n",
        "train_bow_svd = svd.fit_transform(X,y)\n",
        "test_bow_svd = svd.fit_transform(Z)\n",
        "\n",
        "print(y.shape)\n",
        "print(train_bow_svd.shape)\n",
        "print(test_bow_svd.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(111795,)\n",
            "(111795, 100)\n",
            "(47912, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qao07lNZcWtk"
      },
      "source": [
        "### **SVM**\n",
        "\n",
        ">**5-Fold Cross Validation:** In this experiment, the accuracy of the model from the cross validation is ~92%. Its precision is calculated to be ~91.8% (the ratio of correctly predicted observations to the total predicted observations).  The recall is ~90.6%, meaning that this quantum of predicted observations were actually a correct prediction. Finally the f-measure is ~91.2% (the average of precision and recall). \n",
        "This experiment, after being trained with all the train data, it gives a much better score (Accuracy: ~82%). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LILtAY7QimtW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "6f717910-b137-4446-ebaf-83b25f4f1f97"
      },
      "source": [
        "clf = LinearSVC(random_state=42, tol=1e-5, C=0.25)\n",
        "scoring=['accuracy','precision_macro', 'recall_macro', 'f1_macro']\n",
        "scores = cross_validate(clf, train_bow_svd, y, cv=5, n_jobs=4, scoring=scoring)\n",
        "svm_res_svd = pd.DataFrame.from_dict(scores)\n",
        "res_mean = calculate_statistic_metrics(svm_res_svd, res_mean, 'SVM (SVD)', columnNum)\n",
        "display(res_mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Statistic Measure</th>\n",
              "      <th>SVM (BoW)</th>\n",
              "      <th>Random Forest (BoW)</th>\n",
              "      <th>SVM (SVD)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.970008</td>\n",
              "      <td>0.939559</td>\n",
              "      <td>0.922054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.968411</td>\n",
              "      <td>0.940052</td>\n",
              "      <td>0.918617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.965929</td>\n",
              "      <td>0.927771</td>\n",
              "      <td>0.906882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F-measure</th>\n",
              "      <td>0.967147</td>\n",
              "      <td>0.933616</td>\n",
              "      <td>0.912456</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Statistic Measure  SVM (BoW)  Random Forest (BoW)  SVM (SVD)\n",
              "Accuracy            0.970008             0.939559   0.922054\n",
              "Precision           0.968411             0.940052   0.918617\n",
              "Recall              0.965929             0.927771   0.906882\n",
              "F-measure           0.967147             0.933616   0.912456"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vxYk8ksv4KX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "9e28900c-d978-414b-e1d4-334e507bbd73"
      },
      "source": [
        "#Predict for test set\n",
        "y=labels\n",
        "clf.fit(train_bow_svd,y)\n",
        "y_pred_test = clf.predict(test_bow_svd)\n",
        "SVM_pred_svd = create_file(df_test, y_pred_test, 'svm_bow_svd_pred')\n",
        "SVM_pred_svd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Title Content</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262120</td>\n",
              "      <td>Tracy Morgan upgraded to fair condition after ...</td>\n",
              "      <td>actor and comedian tracy morgan has been upgr...</td>\n",
              "      <td>traci morgan upgrad to fair condit after crash...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175132</td>\n",
              "      <td>Smartphones Weigh on Samsung Electronics as Gu...</td>\n",
              "      <td>samsung electronics co ltd on tuesday issued u...</td>\n",
              "      <td>smartphon weigh on samsung electron as guidanc...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>218739</td>\n",
              "      <td>FBI denies fumbling testimony on 'X-Men' direc...</td>\n",
              "      <td>michael f. egan iii said in a press conferenc...</td>\n",
              "      <td>fbi deni fumbl testimoni on x men director bry...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>253483</td>\n",
              "      <td>Bachelorette 2014 Spoilers: Week 3 Recap ??? E...</td>\n",
              "      <td>i am having mixed emotions for what is about ...</td>\n",
              "      <td>bachelorett 2014 spoiler week 3 recap eric hil...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>224109</td>\n",
              "      <td>Barack Obama honours Frankie Knuckles in lette...</td>\n",
              "      <td>u.s. president barack obama has paid a specia...</td>\n",
              "      <td>barack obama honour franki knuckl in letter to...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47907</th>\n",
              "      <td>50348</td>\n",
              "      <td>BMW, Tesla meet to discuss standardizing elect...</td>\n",
              "      <td>june 16, 2014 by edward taylor reutersan emplo...</td>\n",
              "      <td>bmw tesla meet to discuss standard electr car ...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47908</th>\n",
              "      <td>255044</td>\n",
              "      <td>Harrison Ford has been filming the seventh Sta...</td>\n",
              "      <td>he may have helped save the galaxy from the ev...</td>\n",
              "      <td>harrison ford ha been film the seventh star wa...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47909</th>\n",
              "      <td>66502</td>\n",
              "      <td>It's Games, Games, Games As Microsoft Plans To...</td>\n",
              "      <td>less than three months after microsoft had a ...</td>\n",
              "      <td>it s game game game as microsoft plan to close...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47910</th>\n",
              "      <td>10319</td>\n",
              "      <td>App Detail » Microsoft Excel for iPad</td>\n",
              "      <td>app description *** excel is ready for ipad p...</td>\n",
              "      <td>app detail microsoft excel for ipad app detail...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47911</th>\n",
              "      <td>48751</td>\n",
              "      <td>Starbucks Makes Itself More Addictive With Wir...</td>\n",
              "      <td>soon, you'll be able to recharge at starbucks...</td>\n",
              "      <td>starbuck make itself more addict with wireless...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47912 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Id  ...      Predicted\n",
              "0      262120  ...  Entertainment\n",
              "1      175132  ...       Business\n",
              "2      218739  ...  Entertainment\n",
              "3      253483  ...  Entertainment\n",
              "4      224109  ...  Entertainment\n",
              "...       ...  ...            ...\n",
              "47907   50348  ...     Technology\n",
              "47908  255044  ...  Entertainment\n",
              "47909   66502  ...     Technology\n",
              "47910   10319  ...     Technology\n",
              "47911   48751  ...     Technology\n",
              "\n",
              "[47912 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oKSy_yicKfv"
      },
      "source": [
        "## **Random Forest**\n",
        ">**5-Fold Cross Validation:** In this experiment, the accuracy of the model from the cross \n",
        "validation is ~95.1%. Its precision is calculated to be ~94.9% (the ratio of correctly \n",
        "predicted observations to the total predicted observations).  The recall is ~94.1%, \n",
        "meaning that this quantum of predicted observations were actually a correct prediction. \n",
        "Finally the f-measure is ~94.5% (the average of precision and recall). \n",
        "This experiment, after being trained with all the train data, it gives a much better score (Accuracy: ~86%). This is also the experiment that gave us the best prediction results in kaggle leaderboard.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yE5VFlKiwTF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "3e2f7502-785f-4249-a50b-0afda545e2d2"
      },
      "source": [
        "y=labels\n",
        "clf_Rf = RandomForestClassifier(n_jobs=-1)\n",
        "scoring=['accuracy','precision_macro', 'recall_macro', 'f1_macro']\n",
        "scores = cross_validate(clf_Rf, train_bow_svd, y, cv=5, n_jobs=4, scoring=scoring)\n",
        "rf_res_svd = pd.DataFrame.from_dict(scores)\n",
        "res_mean = calculate_statistic_metrics(rf_res_svd, res_mean, 'Random Forest (SVD)', columnNum)\n",
        "display(res_mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Statistic Measure</th>\n",
              "      <th>SVM (BoW)</th>\n",
              "      <th>Random Forest (BoW)</th>\n",
              "      <th>SVM (SVD)</th>\n",
              "      <th>Random Forest (SVD)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.970008</td>\n",
              "      <td>0.939559</td>\n",
              "      <td>0.922054</td>\n",
              "      <td>0.951286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.968411</td>\n",
              "      <td>0.940052</td>\n",
              "      <td>0.918617</td>\n",
              "      <td>0.949943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.965929</td>\n",
              "      <td>0.927771</td>\n",
              "      <td>0.906882</td>\n",
              "      <td>0.941382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F-measure</th>\n",
              "      <td>0.967147</td>\n",
              "      <td>0.933616</td>\n",
              "      <td>0.912456</td>\n",
              "      <td>0.945504</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Statistic Measure  SVM (BoW)  ...  Random Forest (SVD)\n",
              "Accuracy            0.970008  ...             0.951286\n",
              "Precision           0.968411  ...             0.949943\n",
              "Recall              0.965929  ...             0.941382\n",
              "F-measure           0.967147  ...             0.945504\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC5lW0UizjDL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "4a564b0a-9151-498e-9053-2b4c3a706d71"
      },
      "source": [
        "#Predict for test set \n",
        "y=labels\n",
        "clf_Rf = RandomForestClassifier(n_jobs=-1)\n",
        "clf_Rf.fit(train_bow_svd,y)\n",
        "y_pred_test = clf_Rf.predict(test_bow_svd)\n",
        "rf_pred_svd = create_file(df_test, y_pred_test, 'rf_bow_svd_pred')\n",
        "display(rf_pred_svd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Title Content</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262120</td>\n",
              "      <td>Tracy Morgan upgraded to fair condition after ...</td>\n",
              "      <td>actor and comedian tracy morgan has been upgr...</td>\n",
              "      <td>traci morgan upgrad to fair condit after crash...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175132</td>\n",
              "      <td>Smartphones Weigh on Samsung Electronics as Gu...</td>\n",
              "      <td>samsung electronics co ltd on tuesday issued u...</td>\n",
              "      <td>smartphon weigh on samsung electron as guidanc...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>218739</td>\n",
              "      <td>FBI denies fumbling testimony on 'X-Men' direc...</td>\n",
              "      <td>michael f. egan iii said in a press conferenc...</td>\n",
              "      <td>fbi deni fumbl testimoni on x men director bry...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>253483</td>\n",
              "      <td>Bachelorette 2014 Spoilers: Week 3 Recap ??? E...</td>\n",
              "      <td>i am having mixed emotions for what is about ...</td>\n",
              "      <td>bachelorett 2014 spoiler week 3 recap eric hil...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>224109</td>\n",
              "      <td>Barack Obama honours Frankie Knuckles in lette...</td>\n",
              "      <td>u.s. president barack obama has paid a specia...</td>\n",
              "      <td>barack obama honour franki knuckl in letter to...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47907</th>\n",
              "      <td>50348</td>\n",
              "      <td>BMW, Tesla meet to discuss standardizing elect...</td>\n",
              "      <td>june 16, 2014 by edward taylor reutersan emplo...</td>\n",
              "      <td>bmw tesla meet to discuss standard electr car ...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47908</th>\n",
              "      <td>255044</td>\n",
              "      <td>Harrison Ford has been filming the seventh Sta...</td>\n",
              "      <td>he may have helped save the galaxy from the ev...</td>\n",
              "      <td>harrison ford ha been film the seventh star wa...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47909</th>\n",
              "      <td>66502</td>\n",
              "      <td>It's Games, Games, Games As Microsoft Plans To...</td>\n",
              "      <td>less than three months after microsoft had a ...</td>\n",
              "      <td>it s game game game as microsoft plan to close...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47910</th>\n",
              "      <td>10319</td>\n",
              "      <td>App Detail » Microsoft Excel for iPad</td>\n",
              "      <td>app description *** excel is ready for ipad p...</td>\n",
              "      <td>app detail microsoft excel for ipad app detail...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47911</th>\n",
              "      <td>48751</td>\n",
              "      <td>Starbucks Makes Itself More Addictive With Wir...</td>\n",
              "      <td>soon, you'll be able to recharge at starbucks...</td>\n",
              "      <td>starbuck make itself more addict with wireless...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47912 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Id  ...      Predicted\n",
              "0      262120  ...  Entertainment\n",
              "1      175132  ...       Business\n",
              "2      218739  ...  Entertainment\n",
              "3      253483  ...  Entertainment\n",
              "4      224109  ...  Entertainment\n",
              "...       ...  ...            ...\n",
              "47907   50348  ...     Technology\n",
              "47908  255044  ...  Entertainment\n",
              "47909   66502  ...     Technology\n",
              "47910   10319  ...     Technology\n",
              "47911   48751  ...     Technology\n",
              "\n",
              "[47912 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YHm0qizC22h"
      },
      "source": [
        "# **My method - KNN**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        ">[ΚΝΝ](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) is a simple classifier. In our case it scores about the same as the SVM+BoW+SVD experiment. We used it with its default parameters were k=5.\n",
        "\n",
        ">**5-Fold Cross Validation:** In cross validation for KNN we get ~96,4 accuracy. The model’s precision is ~96.2% and the recall ~95.9%. Finally the f-measure is 96.1%. Pretty decent results for the classifier. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G07L5YMB4-IO"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-94npXSwC6Ah"
      },
      "source": [
        "X = train_bow_svd\n",
        "y = labels\n",
        "\n",
        "clf_nb = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWgJ4YC5jEQZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "02f7f55b-2e3b-4669-eaa9-a2121a72551b"
      },
      "source": [
        "scoring=['accuracy','precision_macro', 'recall_macro', 'f1_macro']\n",
        "scores = cross_validate(clf_nb, X, y, cv=5, n_jobs=-1, scoring=scoring)\n",
        "nb_res = pd.DataFrame.from_dict(scores)\n",
        "res_mean = calculate_statistic_metrics(nb_res, res_mean, 'My Method', columnNum)\n",
        "res_mean.to_csv('evaluationResults')\n",
        "display(res_mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Statistic Measure</th>\n",
              "      <th>SVM (BoW)</th>\n",
              "      <th>Random Forest (BoW)</th>\n",
              "      <th>SVM (SVD)</th>\n",
              "      <th>Random Forest (SVD)</th>\n",
              "      <th>My Method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.970008</td>\n",
              "      <td>0.939559</td>\n",
              "      <td>0.922054</td>\n",
              "      <td>0.951286</td>\n",
              "      <td>0.964757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.968411</td>\n",
              "      <td>0.940052</td>\n",
              "      <td>0.918617</td>\n",
              "      <td>0.949943</td>\n",
              "      <td>0.962784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.965929</td>\n",
              "      <td>0.927771</td>\n",
              "      <td>0.906882</td>\n",
              "      <td>0.941382</td>\n",
              "      <td>0.959727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F-measure</th>\n",
              "      <td>0.967147</td>\n",
              "      <td>0.933616</td>\n",
              "      <td>0.912456</td>\n",
              "      <td>0.945504</td>\n",
              "      <td>0.961227</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Statistic Measure  SVM (BoW)  ...  My Method\n",
              "Accuracy            0.970008  ...   0.964757\n",
              "Precision           0.968411  ...   0.962784\n",
              "Recall              0.965929  ...   0.959727\n",
              "F-measure           0.967147  ...   0.961227\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBU7m4RdqKKL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "0b240abf-9b26-4949-e777-b07563e1603a"
      },
      "source": [
        "clf_nb.fit(X,y)\n",
        "y_pred_test = clf_nb.predict(test_bow_svd)\n",
        "rf_pred_svd = create_file(df_test, y_pred_test, 'knn_pred')\n",
        "display(rf_pred_svd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Title Content</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262120</td>\n",
              "      <td>Tracy Morgan upgraded to fair condition after ...</td>\n",
              "      <td>actor and comedian tracy morgan has been upgr...</td>\n",
              "      <td>traci morgan upgrad to fair condit after crash...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175132</td>\n",
              "      <td>Smartphones Weigh on Samsung Electronics as Gu...</td>\n",
              "      <td>samsung electronics co ltd on tuesday issued u...</td>\n",
              "      <td>smartphon weigh on samsung electron as guidanc...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>218739</td>\n",
              "      <td>FBI denies fumbling testimony on 'X-Men' direc...</td>\n",
              "      <td>michael f. egan iii said in a press conferenc...</td>\n",
              "      <td>fbi deni fumbl testimoni on x men director bry...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>253483</td>\n",
              "      <td>Bachelorette 2014 Spoilers: Week 3 Recap ??? E...</td>\n",
              "      <td>i am having mixed emotions for what is about ...</td>\n",
              "      <td>bachelorett 2014 spoiler week 3 recap eric hil...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>224109</td>\n",
              "      <td>Barack Obama honours Frankie Knuckles in lette...</td>\n",
              "      <td>u.s. president barack obama has paid a specia...</td>\n",
              "      <td>barack obama honour franki knuckl in letter to...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47907</th>\n",
              "      <td>50348</td>\n",
              "      <td>BMW, Tesla meet to discuss standardizing elect...</td>\n",
              "      <td>june 16, 2014 by edward taylor reutersan emplo...</td>\n",
              "      <td>bmw tesla meet to discuss standard electr car ...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47908</th>\n",
              "      <td>255044</td>\n",
              "      <td>Harrison Ford has been filming the seventh Sta...</td>\n",
              "      <td>he may have helped save the galaxy from the ev...</td>\n",
              "      <td>harrison ford ha been film the seventh star wa...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47909</th>\n",
              "      <td>66502</td>\n",
              "      <td>It's Games, Games, Games As Microsoft Plans To...</td>\n",
              "      <td>less than three months after microsoft had a ...</td>\n",
              "      <td>it s game game game as microsoft plan to close...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47910</th>\n",
              "      <td>10319</td>\n",
              "      <td>App Detail » Microsoft Excel for iPad</td>\n",
              "      <td>app description *** excel is ready for ipad p...</td>\n",
              "      <td>app detail microsoft excel for ipad app detail...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47911</th>\n",
              "      <td>48751</td>\n",
              "      <td>Starbucks Makes Itself More Addictive With Wir...</td>\n",
              "      <td>soon, you'll be able to recharge at starbucks...</td>\n",
              "      <td>starbuck make itself more addict with wireless...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47912 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Id  ...      Predicted\n",
              "0      262120  ...  Entertainment\n",
              "1      175132  ...       Business\n",
              "2      218739  ...  Entertainment\n",
              "3      253483  ...  Entertainment\n",
              "4      224109  ...  Entertainment\n",
              "...       ...  ...            ...\n",
              "47907   50348  ...     Technology\n",
              "47908  255044  ...  Entertainment\n",
              "47909   66502  ...     Technology\n",
              "47910   10319  ...     Technology\n",
              "47911   48751  ...     Technology\n",
              "\n",
              "[47912 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
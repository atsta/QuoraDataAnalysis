{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q2B.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"fJCslfHF1p_U"},"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.corpus import stopwords\n","from sklearn import linear_model\n","import numpy as np\n","import time\n","import sys\n","from sklearn.model_selection import train_test_split\n","import scipy\n","from sklearn.metrics import log_loss\n","import xgboost as xgb\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import cross_validate\n","from string import digits\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"AA28_XWcu6X0","executionInfo":{"status":"ok","timestamp":1609693557747,"user_tz":-120,"elapsed":1758,"user":{"displayName":"Anna Kavvada","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAbzX3ODuffDmanhnac94SSe9PM816FPvvm62lxQ=s64","userId":"14136556576405742235"}},"outputId":"7dfabf3f-f559-49b6-e2c4-77a99b38453a"},"source":["df = pd.read_csv(\"/content/drive/MyDrive/University/datasets2020/datasets/q2b/train.csv\")\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Question1</th>\n","      <th>Question2</th>\n","      <th>IsDuplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n","      <td>What would happen if the Indian government sto...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>How can I increase the speed of my internet co...</td>\n","      <td>How can Internet speed be increased by hacking...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Why am I mentally very lonely? How can I solve...</td>\n","      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Which one dissolve in water quikly sugar, salt...</td>\n","      <td>Which fish would survive in salt water?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Id  ... IsDuplicate\n","0   0  ...           0\n","1   1  ...           0\n","2   2  ...           0\n","3   3  ...           0\n","4   4  ...           0\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"rLrEXt9Mvk7h","executionInfo":{"status":"ok","timestamp":1609693558046,"user_tz":-120,"elapsed":1162,"user":{"displayName":"Anna Kavvada","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAbzX3ODuffDmanhnac94SSe9PM816FPvvm62lxQ=s64","userId":"14136556576405742235"}},"outputId":"ae165e0e-f53f-4b11-84df-d67a4e289b29"},"source":["df_test = pd.read_csv(\"/content/drive/MyDrive/University/datasets2020/datasets/q2b/test_without_labels.csv\")\n","df_test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Question1</th>\n","      <th>Question2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>283003</td>\n","      <td>What can someone do if they've lost the wirele...</td>\n","      <td>What is the best USB wireless mouse that can b...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>283004</td>\n","      <td>Why India need to elect Prime minister?</td>\n","      <td>Is prime minister of India elected or appointed?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>283005</td>\n","      <td>How can I make money online with free of cost?</td>\n","      <td>How can I make money online for free?</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>283006</td>\n","      <td>Does MDMA affect the first and higher order mo...</td>\n","      <td>Do antipsychotics affect the first and higher ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>283007</td>\n","      <td>I am a Saudi National and have \"SR 3 million\" ...</td>\n","      <td>Where should I invest money to get high returns?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Id  ...                                          Question2\n","0  283003  ...  What is the best USB wireless mouse that can b...\n","1  283004  ...   Is prime minister of India elected or appointed?\n","2  283005  ...              How can I make money online for free?\n","3  283006  ...  Do antipsychotics affect the first and higher ...\n","4  283007  ...   Where should I invest money to get high returns?\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"-0vEv7w1vx3F"},"source":["def getBOW(df, min_df = 100,ngrams = 1,analyzer = 'word'):\n","  # bag of letter sequences (chars)\n","  \"\"\"\n","  BOW = TfidfVectorizer(min_df = min_df, analyzer=analyzer, ngram_range=(1,ngrams), lowercase=True)\n","  \"\"\"\n","\n","  BOW = TfidfVectorizer(min_df = min_df, analyzer=analyzer, ngram_range=(1,ngrams), lowercase=True)\n","\n","  bow_df = pd.DataFrame(pd.concat((df['Question1'],df['Question2'])).unique(), columns=['Concatenated'])\n","\n","  BOW.fit(bow_df['Concatenated'].values.astype('U'))\n","  print('Vocabulary size is {}'.format(len(BOW.vocabulary_)))\n","  return BOW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLW6IhloJlGF"},"source":["def blank_space(x):\n","  return re.sub('[^A-Za-z0-9]+', ' ', x)\n","\n","def numbers(x):\n","  return re.sub(r'[0-9]+', '', x)\n","\n","def standarize_sentence(x):\n","  return ''.join(''.join(word)[:2] for word in x) \n","\n","def apostrophe_words(x):\n","  Apos_dict={\"'s\":\" is\",\"n't\":\" not\",\"'m\":\" am\",\"'ll\":\" will\", \n","           \"'d\":\" would\",\"'ve\":\" have\",\"'re\":\" are\"} \n","  for key,value in Apos_dict.items(): \n","      if key in x: \n","          return x.replace(key,value)\n","  return x\n","\n","def split_words(x):\n","  return \" \".join([word for word in re.split(\"([A-Z][a-z]+[^A-Z]*)\",x) if word])\n","\n","def shallow_cleaning(df):\n","  remove_digits = str.maketrans('', '', digits)\n","  df['Question1'] = df['Question1'].apply(lambda x: blank_space(str(x)))\n","  df['Question1'] = df['Question1'].apply(lambda x: numbers(str(x)))\n","  df['Question1'] = df['Question1'].apply(lambda x: split_words(str(x)))\n","  df['Question1'] = df['Question1'].apply(lambda x: standarize_sentence(str(x)))\n","  df['Question1'] = df['Question1'].apply(lambda x: apostrophe_words(str(x)))\n","  df['Question1'] = df['Question1'].str.strip()\n","  df['Question1'] = df['Question1'].str.lower()\n","\n","  df['Question2'] = df['Question2'].apply(lambda x: blank_space(str(x)))\n","  df['Question2'] = df['Question2'].apply(lambda x: numbers(str(x)))\n","  df['Question2'] = df['Question2'].apply(lambda x: split_words(str(x)))\n","  df['Question2'] = df['Question2'].apply(lambda x: standarize_sentence(str(x)))\n","  df['Question2'] = df['Question2'].apply(lambda x: apostrophe_words(str(x)))\n","  df['Question2'] = df['Question2'].str.strip()\n","  df['Question2'] = df['Question2'].str.lower()\n","  return df\n","\n","#df = shallow_cleaning(df)\n","#df_test = shallow_cleaning(df_test)\n","#df.head()\n","#df_test.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zh5H514zCIea"},"source":["def create_file(data, prediction, filename):\n","  res_df = pd.DataFrame(data)\n","  res_df['Predicted'] = prediction\n","  res_df.to_csv(filename+\".csv\", columns=['Id', 'Predicted'], index=False)\n","  return res_df\n","\n","res_mean = pd.DataFrame([])\n","res_mean = res_mean.rename_axis('Statistic Measure', axis=1)\n","columnNum=0\n","def calculate_statistic_metrics(res, res_mean, columnName, columnNum):\n","  temp_df = pd.DataFrame([])\n","  accuracy_mean = pd.Series(res['test_accuracy'].mean(), name='Accuracy')\n","  precision_mean = pd.Series(res['test_precision_macro'].mean(), name='Precision')\n","  recall_mean = pd.Series(res['test_recall_macro'].mean(), name='Recall')\n","  F1_mean = pd.Series(res['test_f1_macro'].mean(), name='F-measure')\n","  temp_df = temp_df.append(accuracy_mean)\n","  temp_df = temp_df.append(precision_mean)\n","  temp_df = temp_df.append(recall_mean)\n","  temp_df = temp_df.append(F1_mean)\n","  res_mean[columnName] = temp_df[0]\n","  res_mean = res_mean.rename(columns={columnNum:columnName})\n","  return res_mean"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"65fmukn7D1FQ"},"source":["**Logistic Regression**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":694},"id":"7zk5DRz_4fS8","executionInfo":{"status":"ok","timestamp":1609693617726,"user_tz":-120,"elapsed":50241,"user":{"displayName":"Anna Kavvada","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAbzX3ODuffDmanhnac94SSe9PM816FPvvm62lxQ=s64","userId":"14136556576405742235"}},"outputId":"3f59d17f-c197-4d33-9088-5382a888fd43"},"source":["def train_params(min_df = 100,ngrams = 1,analyzer = 'word',train = df, test=df_test):\n","  start_time = time.time()\n","  print('BOW and logistic regression')\n","  BOW = getBOW(train, min_df=min_df,ngrams = ngrams,analyzer = analyzer)\n","  trainq1_trans = BOW.transform(train['Question1'].values.astype('U'))\n","  trainq2_trans = BOW.transform(train['Question2'].values.astype('U'))\n","  labels = train['IsDuplicate'].values\n","\n","  X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n","  y = labels\n","  #X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.33, random_state = 42)\n","  model = linear_model.LogisticRegression(n_jobs=4,solver = 'sag',max_iter = 1000)\n","\n","  print('5-Fold Cross Validation')\n","  scoring=['accuracy','precision_macro', 'recall_macro', 'f1_macro']\n","  scores = cross_validate(model, X, y, cv=5, n_jobs=4, scoring=scoring) \n","  lgr_res = pd.DataFrame.from_dict(scores) \n","  res = calculate_statistic_metrics(lgr_res, res_mean, 'Logistic Regression', columnNum)\n","  display(res)        \n","  \n","  print('fitting ...')\n","  model.fit(X,y)\n","\n","  BOW = getBOW(train, min_df=min_df,ngrams = ngrams,analyzer = analyzer)\n","  testq1_trans = BOW.transform(test['Question1'].values.astype('U'))\n","  testq2_trans = BOW.transform(test['Question2'].values.astype('U'))\n","  X_test = scipy.sparse.hstack((testq1_trans,testq2_trans))\n","  print('predicting ...')\n","  y_pred = model.predict(X_test)\n","\n","  lgr_pred_df = create_file(test, y_pred, 'LGR_pred')\n","\n","  end_time =time.time()\n","  print(\"total time elapsed is {}\".format(end_time-start_time))\n","\n","  display(lgr_pred_df)\n","  return \n","\n","train_params()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BOW and logistic regression\n","Vocabulary size is 3600\n","5-Fold Cross Validation\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>Statistic Measure</th>\n","      <th>Logistic Regression</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Accuracy</th>\n","      <td>0.734816</td>\n","    </tr>\n","    <tr>\n","      <th>Precision</th>\n","      <td>0.719888</td>\n","    </tr>\n","    <tr>\n","      <th>Recall</th>\n","      <td>0.692977</td>\n","    </tr>\n","    <tr>\n","      <th>F-measure</th>\n","      <td>0.699943</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Statistic Measure  Logistic Regression\n","Accuracy                      0.734816\n","Precision                     0.719888\n","Recall                        0.692977\n","F-measure                     0.699943"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["fitting ...\n","Vocabulary size is 3600\n","predicting ...\n","total time elapsed is 49.208916664123535\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Question1</th>\n","      <th>Question2</th>\n","      <th>Predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>283003</td>\n","      <td>What can someone do if they've lost the wirele...</td>\n","      <td>What is the best USB wireless mouse that can b...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>283004</td>\n","      <td>Why India need to elect Prime minister?</td>\n","      <td>Is prime minister of India elected or appointed?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>283005</td>\n","      <td>How can I make money online with free of cost?</td>\n","      <td>How can I make money online for free?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>283006</td>\n","      <td>Does MDMA affect the first and higher order mo...</td>\n","      <td>Do antipsychotics affect the first and higher ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>283007</td>\n","      <td>I am a Saudi National and have \"SR 3 million\" ...</td>\n","      <td>Where should I invest money to get high returns?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>121282</th>\n","      <td>404285</td>\n","      <td>How many keywords are there in the Racket prog...</td>\n","      <td>How many keywords are there in PERL Programmin...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>121283</th>\n","      <td>404286</td>\n","      <td>Do you believe there is life after death?</td>\n","      <td>Is it true that there is life after death?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>121284</th>\n","      <td>404287</td>\n","      <td>What is one coin?</td>\n","      <td>What's this coin?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>121285</th>\n","      <td>404288</td>\n","      <td>What is the approx annual cost of living while...</td>\n","      <td>I am having little hairfall problem but I want...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>121286</th>\n","      <td>404289</td>\n","      <td>What is like to have sex with cousin?</td>\n","      <td>What is it like to have sex with your cousin?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>121287 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["            Id  ... Predicted\n","0       283003  ...         0\n","1       283004  ...         1\n","2       283005  ...         1\n","3       283006  ...         0\n","4       283007  ...         0\n","...        ...  ...       ...\n","121282  404285  ...         0\n","121283  404286  ...         1\n","121284  404287  ...         0\n","121285  404288  ...         0\n","121286  404289  ...         0\n","\n","[121287 rows x 4 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"QBFlYPkCDtuy"},"source":["**Linear SVM**"]},{"cell_type":"code","metadata":{"id":"jyfZCjtTDvtV"},"source":["def train_params(min_df = 100,ngrams = 1,analyzer = 'word',train = df, test = df_test):\r\n","  start_time = time.time()\r\n","  print('BOW and Linear SVM')\r\n","  BOW = getBOW(train, min_df=min_df,ngrams = ngrams,analyzer = analyzer)\r\n","  trainq1_trans = BOW.transform(train['Question1'].values.astype('U'))\r\n","  trainq2_trans = BOW.transform(train['Question2'].values.astype('U'))\r\n","  labels = train['IsDuplicate'].values\r\n","\r\n","  X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\r\n","  y = labels  \r\n","\r\n","  model = linear_model.SGDClassifier(n_jobs=4, penalty='l2', loss='hinge', random_state=42, max_iter = 1000)\r\n","\r\n","  print('5-Fold Cross Validation')\r\n","  scoring=['accuracy','precision_macro', 'recall_macro', 'f1_macro']\r\n","  scores = cross_validate(model, X, y, cv=5, n_jobs=4, scoring=scoring) \r\n","  svm_res = pd.DataFrame.from_dict(scores) \r\n","  res = calculate_statistic_metrics(svm_res, res_mean, 'SVM', columnNum)\r\n","  display(res)        \r\n","  \r\n","  print('fitting ...')\r\n","  model.fit(X,y)\r\n","\r\n","  BOW = getBOW(train, min_df=min_df,ngrams = ngrams,analyzer = analyzer)\r\n","  testq1_trans = BOW.transform(test['Question1'].values.astype('U'))\r\n","  testq2_trans = BOW.transform(test['Question2'].values.astype('U'))\r\n","  X_test = scipy.sparse.hstack((testq1_trans,testq2_trans))\r\n","  print('predicting ...')\r\n","  y_pred = model.predict(X_test)\r\n","\r\n","  svm_pred_df = create_file(test, y_pred, 'SVM_pred')\r\n","\r\n","  end_time = time.time()\r\n","  print(\"total time elapsed is {}\".format(end_time-start_time))\r\n","\r\n","  display(svm_pred_df)\r\n","  return \r\n","\r\n","train_params()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YOWEk7pIHnQz"},"source":["**XGBoost**"]},{"cell_type":"code","metadata":{"id":"5S3ms6JPHmRA"},"source":["import xgboost as xgb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUVk3iVRHwbH"},"source":["def train_params(min_df = 100,ngrams = 1,analyzer = 'word',train = df, test = df_test):\r\n","  start_time = time.time()\r\n","  print('BOW and XGBoost')\r\n","  BOW = getBOW(train, min_df=min_df,ngrams = ngrams,analyzer = analyzer)\r\n","  trainq1_trans = BOW.transform(train['Question1'].values.astype('U'))\r\n","  trainq2_trans = BOW.transform(train['Question2'].values.astype('U'))\r\n","  labels = train['IsDuplicate'].values\r\n","\r\n","  X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\r\n","  y = labels  \r\n","\r\n","  model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss',n_jobs=4)\r\n","  \r\n","  print('5-Fold Cross Validation')\r\n","  scoring=['accuracy','precision_macro', 'recall_macro', 'f1_macro']\r\n","  scores = cross_validate(model, X, y, cv=5, n_jobs=4, scoring=scoring) \r\n","  xgb_res = pd.DataFrame.from_dict(scores) \r\n","  res = calculate_statistic_metrics(xgb_res, res_mean, 'XGB', columnNum)\r\n","  display(res)        \r\n","  \r\n","  print('fitting ...')\r\n","  model.fit(X,y)\r\n","\r\n","  BOW = getBOW(train, min_df=min_df,ngrams = ngrams,analyzer = analyzer)\r\n","  testq1_trans = BOW.transform(test['Question1'].values.astype('U'))\r\n","  testq2_trans = BOW.transform(test['Question2'].values.astype('U'))\r\n","  X_test = scipy.sparse.hstack((testq1_trans,testq2_trans))\r\n","  print('predicting ...')\r\n","  y_pred = model.predict(X_test)\r\n","\r\n","  xgb_pred_df = create_file(test, y_pred, 'XGB_pred')\r\n","\r\n","  end_time = time.time()\r\n","  print(\"total time elapsed is {}\".format(end_time-start_time))\r\n","\r\n","  display(xgb_pred_df)\r\n","  return \r\n","\r\n","train_params()"],"execution_count":null,"outputs":[]}]}